change parameter in type.h
	size	 	// size of board
	MAXIter  	// number of random selfplay following a tree node	
//	learningIter    // number of iterations from restart from root, for continous update of action value
		 	// hard coded in main.c


run run.sh to see the result // change run.sh to change the iteration for averaging 
output folder has some runing result

run plot.r in R to plot the average success for each Roll iter, Learning iter

report.pdf is the write up

Main_Algorithm.pdf, Algorithm2 from Ref3 is the main peusocode
My implementation is not exactly the same, see report or code for detail

Ref folder contains reference paper







